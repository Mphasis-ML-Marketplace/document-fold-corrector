{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e729fcad",
   "metadata": {},
   "source": [
    "# Document Fold Corrector\n",
    "\n",
    " This document correction solution accurately detects and rectifies folds and creases in document images to generate pristine document scans.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "To run this algorithm you need to have access to the following AWS Services:\n",
    "- Access to AWS SageMaker and the model package.\n",
    "- An S3 bucket to specify input/output.\n",
    "- Role for AWS SageMaker to access input/output from S3.\n",
    "\n",
    "This sample notebook shows you how to deploy Synthetic Data Evaluation using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Synthetic Data Evaluation. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Output Result](#D.-Output-Result)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ad202",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f58a5",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page Synthetic Data Evaluation.\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d03f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn='arn:aws:sagemaker:us-east-2:786796469737:model-package/document-dewarping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483a5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from zipfile import ZipFile\n",
    "import uuid\n",
    "import sagemaker as sage\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e37878e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-2-786796469737'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480d6f3",
   "metadata": {},
   "source": [
    "### 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc0962",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b6c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"document-dewarping\"\n",
    "\n",
    "content_type = \"application/zip\"\n",
    "\n",
    "real_time_inference_instance_type = \"ml.m5.large\"\n",
    "batch_transform_inference_instance_type = \"ml.m5.large\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bae84",
   "metadata": {},
   "source": [
    "#### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddace892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.predictor.RealTimePredictor(endpoint, session, content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16836e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a deployable model from model package\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=model_package_arn, \n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c310653a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class RealTimePredictor has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d1ec17",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc87f37b",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "\n",
    "    1) The payload should be in zip format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39cc1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"input.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86089018",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cab80e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"application/zip\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint --endpoint-name $model_name --body fileb://$file_name --content-type 'application/zip' --region us-east-2 output.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8574012",
   "metadata": {},
   "source": [
    "#### D. Output Result\n",
    "\n",
    "- The output file (in zip format) contains the following files:\n",
    "\n",
    "    1. 'output.zip': A folder containing different high resolution images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "712d261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.getcwd()\n",
    "file_name = 'output.zip'\n",
    "\n",
    "file_object = open(file_name,'rb')\n",
    "z = ZipFile(file_object)\n",
    "file_names = []\n",
    "for name in z.namelist():\n",
    "    z.extract(name,file_path)\n",
    "    file_names.append(name)\n",
    "file_object.close()\n",
    "\n",
    "output_folder_path = os.path.join(file_path, \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5bbdef",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c8f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=sage.predictor.Predictor(model_name, sagemaker_session,content_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2790cab0",
   "metadata": {},
   "source": [
    "### 3. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08baa7f3",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e0020ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/document-dewarping\n"
     ]
    }
   ],
   "source": [
    "#upload the batch-transform job input files to S3\n",
    "transform_input_folder = \"data/input/batch\"\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea8970cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\u001b[34m * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://169.254.255.131:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[35m * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://169.254.255.131:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Apr/2023 10:25:25] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Apr/2023 10:25:25] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Apr/2023 10:25:25] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Apr/2023 10:25:25] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34mExtracting all the files now...\u001b[0m\n",
      "\u001b[34mImput Image Dir /opt/program/input.zip\u001b[0m\n",
      "\u001b[35mExtracting all the files now...\u001b[0m\n",
      "\u001b[35mImput Image Dir /opt/program/input.zip\u001b[0m\n",
      "\u001b[34mRead Input Image from : DewarpNet/eval/inp/20230208_142452.jpg\u001b[0m\n",
      "\u001b[35mRead Input Image from : DewarpNet/eval/inp/20230208_142452.jpg\u001b[0m\n",
      "\u001b[32m2023-04-24T10:25:25.139:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mRead Input Image from : DewarpNet/eval/inp/20230206_163045.jpg\u001b[0m\n",
      "\u001b[35mRead Input Image from : DewarpNet/eval/inp/20230206_163045.jpg\u001b[0m\n",
      "\u001b[34mRead Input Image from : DewarpNet/eval/inp/20230208_142446.jpg\u001b[0m\n",
      "\u001b[35mRead Input Image from : DewarpNet/eval/inp/20230208_142446.jpg\u001b[0m\n",
      "\u001b[34mRead Input Image from : DewarpNet/eval/inp/20230208_142455.jpg\u001b[0m\n",
      "\u001b[35mRead Input Image from : DewarpNet/eval/inp/20230208_142455.jpg\u001b[0m\n",
      "\n",
      "\u001b[34m * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://169.254.255.131:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[35m * Serving Flask app 'serve' (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://169.254.255.131:8080/ (Press CTRL+C to quit)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Apr/2023 10:25:25] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Apr/2023 10:25:25] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Apr/2023 10:25:25] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Apr/2023 10:25:25] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34mExtracting all the files now...\u001b[0m\n",
      "\u001b[34mImput Image Dir /opt/program/input.zip\u001b[0m\n",
      "\u001b[35mExtracting all the files now...\u001b[0m\n",
      "\u001b[35mImput Image Dir /opt/program/input.zip\u001b[0m\n",
      "\u001b[34mRead Input Image from : DewarpNet/eval/inp/20230208_142452.jpg\u001b[0m\n",
      "\u001b[35mRead Input Image from : DewarpNet/eval/inp/20230208_142452.jpg\u001b[0m\n",
      "\u001b[32m2023-04-24T10:25:25.139:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:4004: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\u001b[0m\n",
      "\u001b[34mRead Input Image from : DewarpNet/eval/inp/20230206_163045.jpg\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:4004: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\u001b[0m\n",
      "\u001b[35mRead Input Image from : DewarpNet/eval/inp/20230206_163045.jpg\u001b[0m\n",
      "\u001b[34mRead Input Image from : DewarpNet/eval/inp/20230208_142446.jpg\u001b[0m\n",
      "\u001b[35mRead Input Image from : DewarpNet/eval/inp/20230208_142446.jpg\u001b[0m\n",
      "\u001b[34mRead Input Image from : DewarpNet/eval/inp/20230208_142455.jpg\u001b[0m\n",
      "\u001b[35mRead Input Image from : DewarpNet/eval/inp/20230208_142455.jpg\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Apr/2023 10:26:01] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Apr/2023 10:26:01] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Run the batch inference job\n",
    "transformer = model.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "694dff5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-786796469737/document-dewarping-2023-04-24-10-21-07-146'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ouput is available on the following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac751e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name=\"sagemaker-us-east-2-786796469737\"\n",
    "with open('output.zip', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name, os.path.basename(transformer.output_path)+'/input.zip.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06e2ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.getcwd()\n",
    "file_name = 'output.zip'\n",
    "\n",
    "file_object = open(file_name,'rb')\n",
    "z = ZipFile(file_object)\n",
    "file_names = []\n",
    "for name in z.namelist():\n",
    "    z.extract(name,file_path)\n",
    "    file_names.append(name)\n",
    "file_object.close()\n",
    "\n",
    "output_folder_path = os.path.join(file_path, \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a73d50",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8517a",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6503238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7f130",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395a626",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
